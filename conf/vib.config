// Default to /tmp directory if $SCRATCHDIR scratch env is not available,
// see: https://github.com/nf-core/configs?tab=readme-ov-file#adding-a-new-config
def scratch_dir = System.getenv("SCRATCHDIR") ?: "/tmp" //TODO: What is the SCRATCHDIR variable for the VIB cluster?
 
// Specify the work directory
workDir = "$scratch_dir/work"

// Get billing account. This needs to be set in your bashrc.
def billing_account = System.getenv("SLURM_ACCOUNT") ?: "null"

// Reduce the job submit rate to about 50 per minute, this way the server won't be bombarded with jobs
// Limit queueSize to keep job rate under control and avoid timeouts
executor { // TODO: Not sure if you guys have specific submit rates and max queuesize numbers? These numbers are taken from VSC KU Leuven 
    submitRateLimit = '50/1min'
    queueSize = 30
    exitReadTimeout = "10min"
}
 
// Add backoff strategy to catch cluster timeouts and proper symlinks of files in scratch to the work directory
process {
    stageInMode = "symlink"
    stageOutMode = "rsync"
    errorStrategy = { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries    = 5
}

// Specify that singularity should be used and where the cache dir will be for the images
singularity {
    enabled = true
    autoMounts = true
    cacheDir = "$scratch_dir/.singularity" 
}


params {
    config_profile_description = 'VIB cluster profile provided by nf-core/configs.'
    config_profile_contact = 'Luuk Harbers (@ljwharbers)'
    config_profile_url = 'https://datacore.sites.vib.be/en'
    max_memory = 1968.GB //TODO: Is this indeed max mem of hmem nodes (lowered slightly compared to max for overhead)
    max_time = 336.h //TODO: 14 days max wall time is correct?
    max_cpus = 128
}

process {
    resouceLimits = [
        memory: 1968.GB,
        cpus: 128,
        time: 336.h
    ]
    executor = "slurm"
    queue = {
        // TODO: Confirm this is fine please.
        // This should, depending on requested task memory select the proper CPU queue. 
        // Jobs with low memory will go to either the general purpose of the hmem
        // While high mem jobs will only go to hmem partition. 
        // Jobs that require more than 64 cpus also go to hmem 
        //
        // Im not sure what the best way is to also include gpu support here.
        // Any suggestions are welcome, maybe a separate profile for it
        switch (task.memory) { 
            case { it >= 512.GB }:
                return "hmem_128C_256T_2TB"}
            default:
                switch (task.cpus) {
                    case { it > 64 }:
                        return "hmem_128C_256T_2TB"
                    default:
                        return "gp_64C_128T_512GB,hmem_128C_256T_2TB"
                }
    }
    clusterOptions = "--account=$billing_account"
}

